---
layout: splash
title: "MMFood'25"
header:
  overlay_image: /assets/images/banner/food_banner.jpg
  caption: "Join us in Dublin for MMFood'25! We'd also love your help in spreading the word about this workshop."
  actions:
  - label: "<a href='https://acmmm2025.org/' target='_blank' style='display: inline-block; padding: 10px 15px; background-color: transparent; color: white; text-decoration: none; border: 2px solid white; border-radius: 5px; font-weight: bold;' onmouseover='this.style.backgroundColor=\"white\"; this.style.color=\"black\"' onmouseout='this.style.backgroundColor=\"transparent\"; this.style.color=\"white\"'> <i class='fas fa-fw fa-link'></i> ACM Multimedia 2025 </a>"
    url: "#"
  - label: "<a href='/assets/resources/MMFood25_CFP.pdf' target='_blank' style='display: inline-block; padding: 10px 15px; background-color: transparent; color: white; text-decoration: none; border: 2px solid white; border-radius: 5px; font-weight: bold;' onmouseover='this.style.backgroundColor=\"white\"; this.style.color=\"black\"' onmouseout='this.style.backgroundColor=\"transparent\"; this.style.color=\"white\"'> <i class='fas fa-download'></i> Download Call for Papers</a>"
    url: "#"
excerpt: "1st International Workshop on Multi-modal Food Computing"
permalink: /2025/
intro: 
  - excerpt: '<i class="fas fa-map-marker-alt"></i> Venue: Dublin, Ireland ------ <i class="fas fa-calendar-alt"></i> Date: 27/28 October, 2025 <br> <br> <i class="fa-solid fa-circle-info"></i> Host: The MMFood''25 workshop will be hosted on-site at the <b> 33rd ACM International Conference on Multimedia (ACMMM25)</b>. <br> <br> <i class="fa-solid fa-building-columns"></i> Acknowledgement: This workshop has been supported by the <b> Mphasis AI & Applied Tech Lab at Ashoka </b> - a collaboration between Ashoka University and Mphasis Limited (India). <br> <br> <i class="fas fa-envelope"></i> Contact: [mmfood.contact@gmail.com](mailto:mmfood.contact@gmail.com)'

---

{% include feature_row id="intro" type="center" %}


### News
<div class="notice--success">
  <h4>The accepted papers for the MMFood'25 workshop have been announced. Click <a href="/2025/program/" class="alert-link">here</a> to know more.</h4>
</div>
<div class="notice--info">
  <h4>In addition to the full papers (4–8 pages), we also invite short papers (up to 4 pages) that present early-stage work, novel ideas, or innovative applications. More information can be found <a href ="/2025/cfp/#short-paper" class ="alert-link"><b> here.</b></a></h4>
</div>
<div class="notice--info">
  <h4>The deadline for new paper submissions deadline has been extended to <a href ="/2025/cfp/#important-dates" class ="alert-link"><b> 18th July EoD AoE (strict).</b></a></h4>
</div>
<div class="notice--info">
  <h4>The call for papers is open now for MMFood'25! Click <a href="/2025/cfp/" class="alert-link">here</a> to know more.</h4>
</div>
<div class="notice--success">
  <h4>The MMFood'25 program details will be available soon on the website.</h4>
</div>

### Overview
This Multi-modal Food Computing (MMFood'25) workshop will explore the intersection of AI, computer vision, natural language processing, and sensory modeling in understanding food. It aims to advance multimodal methods for food recognition, recommendation, and analysis, addressing challenges in health, nutrition, and sustainability. By bringing together researchers from AI, food science, health informatics, computational social science, and human-computer interaction (HCI), this workshop will foster interdisciplinary collaboration to drive innovation in multimodal food computing.

Several past workshops have addressed specific aspects of food computing but lacked a comprehensive focus on multimodality in food. Our goal is to establish a broader,
more inclusive initiative, starting with a full-day workshop and evolving it into a major activity under SIGMM: ACM Special Interest Group on Multimedia.

#### Multimodal Food Computing

Food computing is inherently multimodal, integrating vision, smell, taste, touch, and language with computational methods to acquire and analyze diverse food-related data. Our perception of food is shaped by multiple sensory inputs and cognitive associations, making food a uniquely multimodal experience. Advances in artificial intelligence, computer vision, natural language processing, and sensory modeling have enabled new ways to recognize, retrieve, recommend, predict, and monitor food, addressing key challenges in health, nutrition, sustainability, and food culture.

In light of AI's growing role in food-related industries — from healthcare and nutrition to sustainability and agroecology — multimodal food computing presents a natural and promising progression into exciting opportunities for both fundamental as well as applied research. Food perception and decision-making involve a fusion of sensory inputs — vision, smell, taste, touch — combined with language, memory, and social influences. Beyond personal choices, geographic, cultural, and socio-economic factors shape food systems and dietary habits, further amplified by digital communities, social media trends, and AI-driven personalization.

This opens up vast opportunities for food computing researchers to harness the power of multimodal intelligence! The ambition of this workshop is to bring together researchers and practitioners working on a wide range of problems related to food computing using various types of food data. It will provide a platform to brainstorm on critical global food-related problems and exchange ideas on how multimodal information can be leveraged to solve them. 

#### Workshop Scope

This workshop will explore multimodal innovations centering food at the intersection of (including but not limited to):

- **Computer Vision** (e.g., food recognition, portion estimation, visual appeal analysis)
- **Natural Language Processing (NLP) & Large Language Models (LLMs)** (e.g., food descriptions, opinions, recipe generation, dietary guidelines)
- **Machine Learning & AI Planning** (e.g., personalized food recommendations, assessing dietary adherence, problems related to food supply-chain and associated logistics)
- **Sensory Science & Multisensory AI** (e.g., perception modeling of taste, smell, texture and other dimensions of food)
- **Behavioral & Social Computing** (e.g., analysis of food trends, digital food communities, understanding cultural influences, detecting early warning signals of food safety and security for risk analysis)

It will also address technical and ethical challenges, such as:

- **Data standardization** across diverse modalities (images, text, nutrition, biometrics)
- **Interpretability of AI-driven food recommendations** and their impact
- **Ensuring inclusivity** in AI-powered food solutions across populations, dietary needs, and eating cultures